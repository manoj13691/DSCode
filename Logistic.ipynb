{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogsiticLoss(X, Y, theta):\n",
    "    h_theta_x = np.dot(X, theta)\n",
    "    \n",
    "    h_theta_x_sigmoid = sigmoid(h_theta_x)\n",
    "    #print(h_theta_x_sigmoid.shape)\n",
    "    \n",
    "    cost = Y * np.log(h_theta_x_sigmoid) + (1-Y) * np.log(1 - h_theta_x_sigmoid) \n",
    "    #print(cost.shape)\n",
    "    cost = np.sum(cost, axis=0)\n",
    "    cost = - cost/len(Y)\n",
    "    print(cost.shape)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(100,1)\n",
    "X_new = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([0 if i<50 else 1 for i in range(100) ]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (100, 1))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.rand(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients defined here - https://math.stackexchange.com/questions/477207/derivative-of-cost-function-for-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(theta, X, Y, learning_rate=0.1, iterations=100):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        cur_cost = LogsiticLoss(X, Y, theta)\n",
    "        print(cur_cost)\n",
    "        # d_theta = np.dot(X.T, (sigmoid(np.dot(X, theta)) - Y))  - correct \n",
    "        # d_theta = np.matmul(X.T , sigmoid(np.matmul(X, theta)) - Y)  -correct\n",
    "        \n",
    "        d_theta = X.T.dot(sigmoid(X.dot(theta)) - Y)\n",
    "        d_theta = d_theta / len(Y)\n",
    "        \n",
    "        theta = theta - learning_rate * d_theta\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradientDescent(theta, X_new, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
